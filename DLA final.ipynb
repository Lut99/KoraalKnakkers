{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1078ca42-5b6d-4ec8-a150-da9c1fe92bb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.animation as animation\n",
    "from copy import copy, deepcopy\n",
    "from scipy import special\n",
    "import pandas as pd\n",
    "import matplotlib as mpl\n",
    "from matplotlib.colors import colorConverter\n",
    "import time\n",
    "import pystencils\n",
    "import sympy\n",
    "from lbmpy.session import *\n",
    "import math\n",
    "from scipy.optimize import curve_fit\n",
    "import os\n",
    "from progressBar import ProgressBar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf91bff5-41ac-419c-8ae1-efa37205171a",
   "metadata": {},
   "outputs": [],
   "source": [
    "### CONSTANTS\n",
    "\n",
    "# The value of the ambient lighting, i.e., when there's a shadow. Should be\n",
    "#   0 <= ambient_strenght <= 1\n",
    "AMBIENT_STRENGTH = 0.25\n",
    "# The value of cells that have direct sunlight. Should be\n",
    "#   0 <= sunlight_strength <= 1\n",
    "SUNLIGHT_STRENGTH = 1.0\n",
    "\n",
    "# Initial force of the lbm simulation\n",
    "FORCE = 1e-7\n",
    "# Determines if the LBM simulation is a box (True) or a more spherical design (False)\n",
    "DUCT = True\n",
    "# The method used in the LBM simulation\n",
    "METHOD = \"cumulant\"\n",
    "# The viscosity of the fluid in the LBM simulation\n",
    "RELAXATION_RATE = 1.9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e9f7c3b-dbb3-4b39-9109-3bce67f4170b",
   "metadata": {},
   "outputs": [],
   "source": [
    "### SUNLIGHT CONCENTRATIONS\n",
    "\n",
    "def spawn_lighty_lighty(N):\n",
    "    \"\"\"\n",
    "        Computes the initial sunlight matrix, i.e., sets everything to the\n",
    "        sunlight value\n",
    "        \n",
    "        Parameters:\n",
    "          - N: The width/height of the box we simulate\n",
    "          \n",
    "        Returns:\n",
    "        An N x N matrix describing the sunlight concentrations for the first\n",
    "        timestep\n",
    "    \"\"\"\n",
    "    \n",
    "    return np.array([[SUNLIGHT_STRENGTH for _ in range(N)] for _ in range(N)])\n",
    "\n",
    "def growth_lighty_lighty(new_pixel, sunlight_mat, copy=True):\n",
    "    \"\"\"\n",
    "        Given the location of the new pixel and the existing sunlight matrix,\n",
    "        we update the sunlight matrices to include the new shadow\n",
    "        \n",
    "        Parameters:\n",
    "          - new_pixels: tuple of (y, x) coordinates for the new pixel\n",
    "          - sunlight_mat: An N x N matrix with the old sunlight concentrations\n",
    "          - copy: If set to True, does not change the sunlight_mat directly but\n",
    "            instead returns a new copy. (Default: True)\n",
    "\n",
    "        Returns:\n",
    "        An N x N matrix with new new sunlight concentrations yaaay\n",
    "    \"\"\"\n",
    "    \n",
    "    # Copy the sunlight matrix if needed\n",
    "    if copy:\n",
    "        sunlight_mat = sunlight_mat.copy()\n",
    "    \n",
    "    # Unpack the pixel coordinates\n",
    "    y, x = new_pixel\n",
    "    \n",
    "    # Set the pixel to 0, to indicate that it's occupied with coral\n",
    "    sunlight_mat[y, x] = 0\n",
    "    \n",
    "    # Loop down from there to 'cast' the shadow\n",
    "    for iy in range(new_pixel[0] - 1, -1, -1):\n",
    "        # If we happen to find a pixel/ambient strength, then we can stop early\n",
    "        if sunlight_mat[iy, x] != SUNLIGHT_STRENGTH:\n",
    "            break\n",
    "        \n",
    "        # Otherwise, cast the shadow\n",
    "        sunlight_mat[iy, x] = AMBIENT_STRENGTH\n",
    "    \n",
    "    # We're done\n",
    "    return sunlight_mat\n",
    "\n",
    "def destroy_lighty_lighty(N, removed_coords, sunlight_mat, object_mat, copy = True):\n",
    "    \"\"\"\n",
    "        Given lists of pixels that are removed, recomputes the shadow on their\n",
    "        columns.\n",
    "        \n",
    "        Parameters:\n",
    "          - N: The width/height of the box we simulate\n",
    "          - removed_coords: List of (y, x) tuples describing each of the pixels\n",
    "          - sunlight_mat: N x N matrix describing the sunlight concentrations\n",
    "            at the previous step.\n",
    "          - object_mat: N x N matrix of 1's and 0's describing where the coral\n",
    "            lives. Assumes that the removed pixels have already been removed.\n",
    "          - copy: If set to True, does not change the sunlight_mat directly but\n",
    "            instead returns a new copy. (Default: True)\n",
    "        \n",
    "        Returns:\n",
    "        An N x N matrix describing the sunlight at the next timestep\n",
    "    \"\"\"\n",
    "    \n",
    "    # Copy the sunlight matrix if needed\n",
    "    if copy:\n",
    "        sunlight_mat = sunlight_mat.copy()\n",
    "        \n",
    "    # Find the unique columns\n",
    "    columns = set({ coord[1] for coord in removed_coords })\n",
    "    \n",
    "    # Loop thru the columns\n",
    "    for x in columns:\n",
    "        # Loop thru the column itself, spreading sunlight where we go\n",
    "        for y in range(N - 1, -1, -1):\n",
    "            # If it's a coral, then we can assume the rest is still shadow\n",
    "            if object_mat[y, x] == 1:\n",
    "                break\n",
    "            \n",
    "            # Otherwise, set the big sunlight\n",
    "            sunlight_mat[y, x] = SUNLIGHT_STRENGTH\n",
    "    \n",
    "    # We're done already\n",
    "    return sunlight_mat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3ca1a4c-3d84-4dcb-8937-29ef4a95791e",
   "metadata": {},
   "outputs": [],
   "source": [
    "### FLOW CONCENTRATIONS\n",
    "\n",
    "def velocity_info_callback(boundary_data, activate=True, **_):\n",
    "    \"\"\"\n",
    "        Function to be able to activate and deactivate inflow speed\n",
    "        \n",
    "        Parameters:\n",
    "          - boundary_data: the data for the lbmpy package that defines the\n",
    "            boundary conditions\n",
    "          - activate: whether or not the flow is activated\n",
    "    \"\"\"\n",
    "    boundary_data['vel_1'] = 0\n",
    "    if activate==True:\n",
    "        u_max = 0.05\n",
    "        boundary_data['vel_0'] = u_max \n",
    "    else:\n",
    "        boundary_data['vel_0'] = 0\n",
    "\n",
    "\n",
    "def init_flow(seed_coord_x, N, initial_iterations = 50):\n",
    "    \"\"\"\n",
    "        Function to initialize the flow density matrix. Also runs it a couple\n",
    "        of times to spread the flow a lil'.\n",
    "        \n",
    "        Parameters:\n",
    "          - seed_coord_x: The x-coordinate of the seed\n",
    "          - N: The width/height of the box we simulate\n",
    "          - initial_iterations: The number of iterations we run the simulation\n",
    "            to get the flow going a little bit. (Default: 50)\n",
    "\n",
    "        Returns:\n",
    "          - A new LBMpy object with the prepared scenario\n",
    "          - Snapshots_vel: List that contains the snapshots of the flow, for\n",
    "            plotting\n",
    "    \"\"\"\n",
    "    \n",
    "    # Initialize the LBMpy object\n",
    "    initial_velocity = np.zeros((N, N) + (2,))\n",
    "    initial_velocity[:, :, 0] =  0.08\n",
    "    scenario = create_fully_periodic_flow(\n",
    "        initial_velocity,\n",
    "        method='cumulant',\n",
    "        relaxation_rate=1.9\n",
    "    )\n",
    "    \n",
    "    # Set the boundary of the LBM\n",
    "    stencil = get_stencil(\"D2Q9\")\n",
    "    outflow = ExtrapolationOutflow(stencil[4], scenario.method)\n",
    "    scenario.boundary_handling.set_boundary(outflow, make_slice[:,N])\n",
    "    inflow = UBB(velocity_info_callback, dim=scenario.method.dim)\n",
    "    scenario.boundary_handling.set_boundary(inflow, make_slice[0, :])\n",
    "    scenario.boundary_handling.set_boundary(NoSlip(), make_slice[:, 0])\n",
    "    \n",
    "    # Prepare the simulation with only the seed pixel\n",
    "    flag = scenario.boundary_handling.set_boundary(NoSlip(), make_slice[seed_coord_x, 0])\n",
    "    \n",
    "    # List to save snapshots\n",
    "    snapshots_vel = []\n",
    "    snapshots_vec = []\n",
    "    \n",
    "    # Run the simulation n times\n",
    "    for _ in range(initial_iterations):\n",
    "        scenario.run(1)\n",
    "        snappy = deepcopy(scenario.velocity[:,:,0])\n",
    "        snapshots_vel.append(snappy)\n",
    "        snapshots_vec.append(deepcopy(scenario.velocity_slice()))\n",
    "    \n",
    "    # The scenario is noweth ready\n",
    "    return scenario, snapshots_vel, snapshots_vec\n",
    "\n",
    "\n",
    "def update_flow(object_mat, scenario, snapshots_vel, snapshots_vec, n_steps = 1):\n",
    "    \"\"\"\n",
    "        Function to compute the flow density matrix ed for the next time step.\n",
    "\n",
    "        Parameters:\n",
    "          - object_mat: N x N matrix describing where the coral lives.\n",
    "          - scenario: LBMpy scenario describing the flow at the previous\n",
    "            timestep\n",
    "          - snaptshots_vel: List of snapshots of velocities, for the movies\n",
    "          - n_steps: How many steps to update the flow (Default: 1)\n",
    "\n",
    "        Returns:\n",
    "        A tuple of:\n",
    "          - The given LBM scenario\n",
    "          - The list of snapshots of the velocity, for el movie\n",
    "    \"\"\"\n",
    "\n",
    "    # set noslip boundary around object\n",
    "    for y in range(N - 1):\n",
    "        for x in range(1, N - 1):\n",
    "            if object_mat[y, x] == 1:\n",
    "                flag = scenario.boundary_handling.set_boundary(NoSlip(), make_slice[x, y])\n",
    "    \n",
    "    # run lbm 10 steps, saving at each step for movie\n",
    "    for _ in range(n_steps):\n",
    "        scenario.run(1)\n",
    "        snappy = deepcopy(scenario.velocity[:,:,0])\n",
    "        snapshots_vel.append(snappy)\n",
    "        snapshots_vec.append(deepcopy(scenario.velocity_slice()))\n",
    "    return scenario, snapshots_vel, snapshots_vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12072e07-b88d-41a9-9d27-fb55e7f4f138",
   "metadata": {},
   "outputs": [],
   "source": [
    "### NUTRIENT CONCENTRATIONS\n",
    "\n",
    "def diffusion_update(conc_mat, omega):\n",
    "    \"\"\"\n",
    "        Function to calculate the difference in the nutrient concentration\n",
    "        based on the diffusion.\n",
    "        Uses SOR method, only right boundary is calculated (rest are sink\n",
    "        boundaries, with standard set to 0)\n",
    "        \n",
    "        Parameters:\n",
    "          - conc_mat: nutrient concentration matrix\n",
    "          - omega: relaxation parameter\n",
    "        \n",
    "        Returns:\n",
    "        A matrix with the difference in nutrient concentration caused by diffusion.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Initialize the update result\n",
    "    diff_update = np.zeros((N,N))\n",
    "\n",
    "    # middle of matrix\n",
    "    for j in range(1,N-1):\n",
    "        for i in range(1,N-1):\n",
    "            diff_update[i][j] = (omega/4)*(conc_mat[i+1][j] + conc_mat[i-1][j] + conc_mat[i][j+1] + conc_mat[i][j-1]) - omega*conc_mat[i][j]\n",
    "\n",
    "    # right boundary\n",
    "    for k in range(1,N-1):\n",
    "        diff_update[k][N-1] = omega/4*(conc_mat[k+1][N-1] + conc_mat[k-1][N-1]  + conc_mat[k][N-2]) - omega*conc_mat[k][N-1] # + conc_mat[k][0]\n",
    "\n",
    "    return diff_update\n",
    "\n",
    "\n",
    "def convection_update(nut_mat, scenario):\n",
    "    \n",
    "    \"\"\"\n",
    "        Calculates the difference in nutrient concentration caused by the\n",
    "        convection (flow).\n",
    "        \n",
    "        Parameters:\n",
    "          - nut_mat: nutrient concentration matrix\n",
    "          - scenario = channel with lattice Boltzmann flow, velocity profile.\n",
    "        \n",
    "        Returns:\n",
    "        Matrix with the difference in nutrient concentration caused by\n",
    "        convection.\n",
    "    \"\"\"\n",
    "    \n",
    "    # TODO: Ask Malou if this flip goes alright\n",
    "    # Prepare the result matrix\n",
    "    conv_update = np.zeros((N, N))\n",
    "    velocties = scenario.velocity_slice()\n",
    "    \n",
    "    # flow to the right\n",
    "    conv_flow_right = np.transpose(velocties[:-1,:,0])*nut_mat[:,:-1]\n",
    "    conv_flow_right[np.where(conv_flow_right < 0)] = 0\n",
    "    conv_update[:,:-1] -= conv_flow_right\n",
    "    conv_update[:,1:] += conv_flow_right\n",
    "    \n",
    "    # flow to the left\n",
    "    conv_flow_left = np.transpose(velocties[2:,:,0])*nut_mat[:,2:]\n",
    "    conv_flow_left[np.where(conv_flow_left > 0)] = 0\n",
    "    conv_update[:,2:] -= conv_flow_left\n",
    "    conv_update[:,1:-1] += conv_flow_left\n",
    "    \n",
    "    # flow up \n",
    "    conv_flow_up = np.transpose(velocties[1:,:-1,1])*nut_mat[:-1,1:]\n",
    "    conv_flow_up[np.where(conv_flow_up < 0)] = 0\n",
    "    conv_update[:-1,1:] -= conv_flow_up\n",
    "    conv_update[1:,1:] += conv_flow_up\n",
    "    \n",
    "    # flow down\n",
    "    conv_flow_down = np.transpose(velocties[1:,1:,1])*nut_mat[1:,1:]\n",
    "    conv_flow_down[np.where(conv_flow_down > 0)] = 0\n",
    "    conv_update[1:,1:] -= conv_flow_down\n",
    "    conv_update[:-1,1:] += conv_flow_down\n",
    "    \n",
    "    # done\n",
    "    return conv_update\n",
    "\n",
    "\n",
    "def init_nut(N, omega, object_mat, scenario, nut_inflow, initial_iterations = 2000):\n",
    "    \"\"\"\n",
    "        Initializes the nutrition matrix by running it a lot of times.\n",
    "        \n",
    "        Parameters:\n",
    "          - N: The width/height of the box we simulate\n",
    "          - omega: Relaxation parameter\n",
    "          - object_mat: N x N coral matrix of 1's and 0's\n",
    "          - scenario: The LBMpy object needed for the flow part of the\n",
    "            computation\n",
    "          - snapshots_grad: List of snapshots of the gradient for animation.\n",
    "          - nut_inflow: The strength of the new nutrition concentrations that\n",
    "            spawn\n",
    "          - initial_iterations: Number of iterations to 'dry run' the nutrition\n",
    "            (Default: 2000)\n",
    "        \n",
    "        Returns:\n",
    "        The nutrition matrix, ready to let coral grow\n",
    "    \"\"\"\n",
    "    \n",
    "    # Spawn the matrices\n",
    "    nut_mat = np.zeros((N, N))\n",
    "    snapshots_grad = []\n",
    "    \n",
    "    # Set the boundries\n",
    "    nut_mat[:, 0:int(N / 10)] = nut_inflow\n",
    "    \n",
    "    # Update the nutrition matrix the desried number of times\n",
    "    for _ in range(initial_iterations):\n",
    "        # Perform the update\n",
    "        nut_mat = update_nut(nut_mat, omega, scenario, object_mat, nut_inflow, copy=False)\n",
    "        snapshots_grad.append(nut_mat.copy())\n",
    "    \n",
    "    # Return\n",
    "    return nut_mat, snapshots_grad\n",
    "\n",
    "\n",
    "def update_nut(nut_mat, omega, scenario, object_mat, nut_inflow, copy=True):\n",
    "    \"\"\"\n",
    "        Combines the convection matrix and diffusion matrix.\n",
    "        \n",
    "        Parameters:\n",
    "          - nut_mat: The nutrition matrix at the previous timestep\n",
    "          - omega: relaxation parameter\n",
    "          - scenario: object for the LBMpy simulation s.t. it knows its state\n",
    "          - object_mat: N x N matrix that describes the coral once again\n",
    "          - nut_inflow: The strength of the new nutrition concentrations that\n",
    "            spawn\n",
    "          - copy: Whether or not to copy the nut_mat before altering it.\n",
    "            (Default: True)\n",
    "        \n",
    "        Returns:\n",
    "        The new nutrition matrix\n",
    "    \"\"\"\n",
    "\n",
    "    # If we want to copy, then copy the nut_mat\n",
    "    if copy:\n",
    "        nut_mat = nut_mat.copy()\n",
    "        \n",
    "    # Compute the convection & diffusion parts of the update first\n",
    "    update_diff = diffusion_update(nut_mat, 0.7)\n",
    "    update_conv = convection_update(nut_mat, scenario)\n",
    "    \n",
    "    # Perform the update\n",
    "    nut_mat += update_conv + update_diff\n",
    "    \n",
    "    # Fix the negative values in the matrix for stability\n",
    "    nut_mat[nut_mat < 0] = 0\n",
    "    \n",
    "    # Also set the coral values to have no nutritions (coral isn't edible apparently)\n",
    "    nut_mat[object_mat == 1] = 0\n",
    "    \n",
    "    # Fix the boundries of the nutrient matrix\n",
    "    nut_mat[:,  0] = nut_inflow\n",
    "    nut_mat[:, -1] = 0\n",
    "    nut_mat[ 0, :] = 0\n",
    "    nut_mat[-1, :] = 0\n",
    "    \n",
    "    # Done\n",
    "    return nut_mat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0e4f380-2875-419e-bdc2-054367ff2973",
   "metadata": {},
   "outputs": [],
   "source": [
    "### EROSION\n",
    "\n",
    "def coral_breaky_breaky(N, seed_coord_x, threshold, object_mat, scenario, sunlight_mat, copy=True):\n",
    "    \"\"\"\n",
    "        Function that computes if the coral is gonna breaky breaky\n",
    "        \n",
    "        Parameters:\n",
    "          - N: The width/height of the box we simulate in\n",
    "          - seed_coord_x: the x-coordinate of the seed of the coral (the y is\n",
    "            assumed to be 0)\n",
    "          - threshold: The maximum force before a coral block erodes away\n",
    "          - object_mat: a numpy array of 0's and 1's that determine where\n",
    "            the coral is\n",
    "          - scenario: LBMpy object that describes the current flow status\n",
    "          - sunlight_mat: N x N matrix describing the sunlights, which will be\n",
    "            updated in case a pixels breaks.\n",
    "          - copy: If True, does not modify the original object but instead\n",
    "            returns a new one\n",
    "          \n",
    "        Returns:\n",
    "          - The coral matrix with the relevant pixels removed\n",
    "          - Broken boolean: True if part of coral got removed, else False\n",
    "          \n",
    "        O.O does it work?\n",
    "    \"\"\"\n",
    "    \n",
    "    # Copy the matrix if the user so desires\n",
    "    if copy:\n",
    "        object_mat = object_mat.copy()\n",
    "\n",
    "    # Keep track whether part of coral has broken off\n",
    "    broken = False\n",
    "\n",
    "    # Loop through the coral matrix to find the corals\n",
    "    vector_field = scenario.velocity\n",
    "    for y in range(N):\n",
    "        for x in range(N):\n",
    "            if (x == seed_coord_x and y == 0) or object_mat[y, x] == 0: continue\n",
    "\n",
    "            # Compute the pressure at this point (i.e., length of the vector)\n",
    "            pressure = math.sqrt(vector_field[y, x][0]**2 + vector_field[y, x][1]**2)\n",
    "\n",
    "            # If the pressure exceeds the threshold, remove the coral (:()\n",
    "            if pressure > threshold:\n",
    "                object_mat[y, x] = 0\n",
    "                \n",
    "                # Remove the object from the scenario as well\n",
    "                scenario.boundary_handling.set_boundary('domain', make_slice[x, y])\n",
    "                \n",
    "                # Recompute the sunlight for this removed pixel\n",
    "                destroy_lighty_lighty(N, [(y, x)], sunlight_mat, object_mat, False)\n",
    "                broken = True\n",
    "\n",
    "    # We're done! Return the results\n",
    "    return object_mat, broken\n",
    "\n",
    "\n",
    "def coral_painty_painty(seed_coord_x, object_mat, sunlight_mat, scenario, copy=True):\n",
    "    \"\"\"\n",
    "        Function that checks which pixels are still connected to the source,\n",
    "        and removes them. Also returns a new list of potential growth\n",
    "        candidates.\n",
    "        \n",
    "        Note: We assume that a diagonal connection == no connection\n",
    "        \n",
    "        Parameters:\n",
    "          - seed_coord_x: the x-coordinate of the seed of the coral (the y is\n",
    "            assumed to be 0)\n",
    "          - object_mat: a numpy array of 0's and 1's that determine where\n",
    "            the coral is\n",
    "          - sunlight_mat: N x N matrix describing the sunlights, which will be\n",
    "            updated in case a pixels breaks.\n",
    "          - scneario: LBMpy object describing the flow matrix\n",
    "          - copy: If True, does not modify the original object but instead returns a new one\n",
    "        \n",
    "        Returns:\n",
    "        A tuple of:\n",
    "          - The coral matrix, with all the unconnected pixels removed\n",
    "          - A new list of growth candidates\n",
    "    \"\"\"\n",
    "    \n",
    "    # Copy the matrix if the user so desires\n",
    "    if copy:\n",
    "        object_mat = object_mat.copy()\n",
    "        \n",
    "    # Do a breadth-first search starting at the seed to see which pixels are connected to the seed\n",
    "    object_mat[0, seed_coord_x] = 2\n",
    "    to_do = [(0, seed_coord_x)]\n",
    "    candidates = set()\n",
    "    while len(to_do) > 0:\n",
    "        # Fetch the pixel to check\n",
    "        y, x = to_do[0]\n",
    "        to_do = to_do[1:]\n",
    "        \n",
    "        # Get the area around the pixel\n",
    "        for neighbour in [(-1, 0), (0, 1), (1, 0), (0, -1)]:\n",
    "            ny = y + neighbour[0]\n",
    "            nx = x + neighbour[1]\n",
    "\n",
    "            # Skip if the pixel is out-of-bounds\n",
    "            if nx < 0 or nx > object_mat.shape[0] - 1 or ny < 0 or ny > object_mat.shape[1] - 1:\n",
    "                continue\n",
    "\n",
    "            # If the pixel is not a pixel, then store it as possible growth candidate\n",
    "            if object_mat[ny, nx] == 0:\n",
    "                candidates.add((ny, nx))\n",
    "            \n",
    "            # If it is an (unvisited) pixel, then mark as visited/connected and add it to the todo list\n",
    "            if object_mat[ny, nx] == 1:\n",
    "                # Mark the pixel as connected\n",
    "                object_mat[ny, nx] = 2\n",
    "                \n",
    "                # Add to the queue\n",
    "                to_do.append((ny, nx))\n",
    "    \n",
    "    # Fetch the coordinates of the 1's\n",
    "    removed_pixels = np.where(object_mat == 1)\n",
    "    removed_coords = list(zip(*removed_pixels))\n",
    "    \n",
    "    # Go thru the matrix again and remove anything that's a 1\n",
    "    object_mat[object_mat == 1] = 0\n",
    "    # Convert the visited pixels back to 1's\n",
    "    object_mat[object_mat == 2] = 1\n",
    "    \n",
    "    # Also remove the object from the scenario\n",
    "    for y, x in removed_coords:\n",
    "        scenario.boundary_handling.set_boundary('domain', make_slice[int(x), int(y)])\n",
    "    \n",
    "    # Update the sunlight matrix to get rid of the ol' shadows\n",
    "    destroy_lighty_lighty(N, removed_coords, sunlight_mat, object_mat, False)\n",
    "    \n",
    "    # Done!\n",
    "    return object_mat, candidates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "223cc2df-623f-43e0-a957-f0c76dbe967f",
   "metadata": {},
   "outputs": [],
   "source": [
    "### GAME LOOP\n",
    "\n",
    "def get_candidates(object_loc, object_mat, candidates):\n",
    "    \"\"\"\n",
    "        Function to find the neighbours of an object cell,\n",
    "        if they qualify as growth candidates, add to set \n",
    "        (so all candidates are unique).\n",
    "        \n",
    "        Parameters:\n",
    "          - object_loc: coordinates tuple of new object cell\n",
    "          - object_mat: a numpy array of 0's and 1's that determine where\n",
    "            the object is\n",
    "          - candidates: a set of tuples containing the candidate coordinates\n",
    "        \n",
    "        Returns:\n",
    "        The updated candidate set\n",
    "    \"\"\"\n",
    "\n",
    "    # Get object coordinates\n",
    "    y = object_loc[0]\n",
    "    x = object_loc[1]\n",
    "\n",
    "    # check if edirect neighbours are NOT part of object, and add them to candidates\n",
    "    if x != N - 1 and object_mat[y][x + 1] == 0:\n",
    "        candidates.add((y, x + 1))\n",
    "        \n",
    "    if x != 0 and object_mat[y][x - 1] == 0:\n",
    "        candidates.add((y, x - 1))\n",
    "        \n",
    "    if y != N - 1 and object_mat[y + 1][x] == 0:\n",
    "        candidates.add((y + 1, x))\n",
    "        \n",
    "    if y != 0 and object_mat[y - 1][x] == 0:\n",
    "        candidates.add((y - 1, x))\n",
    "\n",
    "    return candidates\n",
    "\n",
    "\n",
    "def choose_growth(N, eta, alpha, sunlight_mat, nut_mat, candidates, object_mat):\n",
    "    \"\"\"\n",
    "        Function to calculate growth probabilities of each candidate cell,\n",
    "        choose one and grow it this timestep.\n",
    "        \n",
    "        Also breaks the coral due to errosion.\n",
    "\n",
    "        Parameters:\n",
    "          - N: grid size (NxN)\n",
    "          - eta: weight of concentration gradient for growth\n",
    "          - alpha: weight of influence of sun vs nutrients\n",
    "          - sunlight_mat: numpy array containing all sunlight concentrations\n",
    "            per coordinate\n",
    "          - candidates: set of tuple coordinates of all growable cells \n",
    "          - object_mat: N x N array of 1's and 0's describing where the color\n",
    "            is\n",
    "\n",
    "        Returns:\n",
    "        - Location of the new pixel as (y, x) tuple\n",
    "        - Updated object_mat matrix with newly grown object cell\n",
    "        - Updated candidate set\n",
    "    \"\"\"\n",
    "    \n",
    "    probs = []  # store all candidate grow probabilities\n",
    "    list_candidates = list(candidates)  # ensure same ordering \n",
    "    \n",
    "    # Normalize the sun concentrations to probabilities\n",
    "    total = np.sum([sunlight_mat[cand] ** eta for cand in list_candidates])\n",
    "    if total == 0:\n",
    "        probs_sun = [1 / len(list_candidates) for _ in list_candidates]\n",
    "    else:\n",
    "        probs_sun = [sunlight_mat[cand] ** eta / total for cand in list_candidates]\n",
    "    \n",
    "    # Normalize the nutritient concentrations to probabilities\n",
    "    total = np.sum([nut_mat[cand] ** eta for cand in list_candidates])\n",
    "    if total == 0:\n",
    "        probs_nut = [1 / len(list_candidates) for _ in list_candidates]\n",
    "    else:\n",
    "        probs_nut = [(nut_mat[cand] ** eta) / total for cand in list_candidates]\n",
    "    \n",
    "    # Join them together using the alpha weighted average\n",
    "    probs = [alpha * probs_sun[i] + (1 - alpha) * probs_nut[i] for i in range(len(list_candidates))]\n",
    "\n",
    "    # Choose a candidate and grow\n",
    "    chosen_growth = list_candidates[np.random.choice(len(candidates), p=probs)]\n",
    "    object_mat[chosen_growth] = 1\n",
    "    sunlight_mat[chosen_growth] = 0\n",
    "    # Update candidate set after growth\n",
    "    candidates = get_candidates(chosen_growth, object_mat, candidates)\n",
    "    # Delete newly grown cell from growth candidates\n",
    "    candidates.remove(chosen_growth)\n",
    "\n",
    "    # Possibly break the coral\n",
    "    return chosen_growth, object_mat, candidates\n",
    "\n",
    "\n",
    "def SOR_DLA_to_solution(N, eta, omega, alpha, threshold, nut_inflow, iterations):\n",
    "    \"\"\"\n",
    "        Function to calculate the SOR of a grid with object, \n",
    "        until convergence, with growing object\n",
    "        \n",
    "        Parameters:\n",
    "          - N: desired grid size (NxN)\n",
    "          - eta: weight of concentration gradient for growth\n",
    "          - omega: SOR equation constant\n",
    "          - alpha: weight of influence of sun vs nutrients\n",
    "          - nut_inflow: The strenght of new nutrients that spawn left in the\n",
    "            box.\n",
    "          - iterations: how many times the object should grow\n",
    "        \n",
    "        Returns:\n",
    "        - The concentration matrix\n",
    "        - The object_mat matrix with fully grown object\n",
    "        - The densitity list with coral density at each iteration\n",
    "    \"\"\"\n",
    "    \n",
    "    # Compute the source location (middle)\n",
    "    seed_coord_x = int(N / 2)\n",
    "\n",
    "    # Keep track of coral density at each iteration\n",
    "    density_list = []\n",
    "    \n",
    "    # Initalisation of matrix with seed of object\n",
    "    object_mat = np.zeros((N, N))\n",
    "    object_mat[0, seed_coord_x] = 1\n",
    "    candidates = set()\n",
    "    candidates = get_candidates((0, seed_coord_x), object_mat, candidates)\n",
    "    \n",
    "    # Initialize starting concentrations\n",
    "    sunlight_mat = spawn_lighty_lighty(N)\n",
    "    scenario, snapshots_vel, snapshots_vec = init_flow(seed_coord_x, N)\n",
    "    nut_mat, snapshots_grad = init_nut(N, omega, object_mat, scenario, nut_inflow, initial_iterations=2000)\n",
    "\n",
    "    # Prepend the 50 iterations of nutrients to compensate for the velocities\n",
    "    snapshots_grad = [np.zeros((N, N)) for _ in range(50)] + snapshots_grad\n",
    "    \n",
    "    # Append the flow with 2000 iterations to compensate for the nut\n",
    "    snapshots_vel += [scenario.velocity[:, :, 0].copy() for _ in range(2000)]\n",
    "    snapshots_vec += [scenario.velocity_slice().copy() for _ in range(2000)]\n",
    "    \n",
    "    # Generate the sunlight and object snapshot, with enough iterations to cover the timespan of the scenario\n",
    "    snapshots_sun = [sunlight_mat.copy() for _ in range(2050)]\n",
    "    snapshots_obj = [object_mat.copy() for _ in range(2050)]\n",
    "\n",
    "    # Loop until object is grown 'iterations' times, recomputing the sunlight with each growth\n",
    "    for _ in range(iterations):\n",
    "        # Grow the coral\n",
    "        new_pixel, object_mat, candidates = choose_growth(N, eta, alpha, sunlight_mat, nut_mat, candidates, object_mat)\n",
    "        snapshots_obj.append(object_mat.copy())\n",
    "        \n",
    "        # Update the flow using Lattice-Boltzmann\n",
    "        scenario, snapshots_vel, snapshots_vec = update_flow(object_mat, scenario, snapshots_vel, snapshots_vec)\n",
    "        \n",
    "        # Update the sunlight matrix according to the new pixel\n",
    "        sunlight_mat = growth_lighty_lighty(new_pixel, sunlight_mat, copy=False)\n",
    "        snapshots_sun.append(sunlight_mat.copy())\n",
    "        \n",
    "        # Compute the nutrient concentration matrix for the next timestep\n",
    "        nut_mat = update_nut(nut_mat, omega, scenario, object_mat, nut_inflow, copy=False)\n",
    "        snapshots_grad.append(nut_mat.copy())\n",
    "        \n",
    "        # Finally, break the coral based on the vectors generated by the LBM\n",
    "        _, broken = coral_breaky_breaky(N, seed_coord_x, threshold, object_mat, scenario, sunlight_mat, copy=False)\n",
    "        if broken:\n",
    "            _, candidates = coral_painty_painty(seed_coord_x, object_mat, sunlight_mat, scenario, copy=False)\n",
    "        \n",
    "        # Compute the branch factor/density of the graph for analysis\n",
    "        density_list.append(branch_factor(object_mat))\n",
    "\n",
    "    # We're done!\n",
    "    return snapshots_obj, snapshots_vel, snapshots_vec, snapshots_sun, snapshots_grad, density_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01677ea5-1ec1-440b-901d-be006afc3525",
   "metadata": {},
   "outputs": [],
   "source": [
    "### DENSITY / ANALYSIS\n",
    "\n",
    "def branch_factor(coral_matrix):\n",
    "    \"\"\"\n",
    "        Function that computes The fraction of coral cells which are edge cells. \n",
    "        The lower the number the more dense the coral is.\n",
    "        Parameters:\n",
    "          - coral matrix\n",
    "        \n",
    "        Returns:\n",
    "            The fraction of cells which are touching the sea.\n",
    "    \"\"\"\n",
    "    edge_cells = set()\n",
    "    coral_size = 0\n",
    "    for row in range(len(coral_matrix)):\n",
    "        for element in range(len(coral_matrix)):\n",
    "            # If cell is not coral, continue            \n",
    "            if coral_matrix[row][element] == 0:\n",
    "                continue\n",
    "            else:\n",
    "                coral_size += 1\n",
    "                # Check all neighbours\n",
    "                for neighbour in [(-1, 0), (0, 1), (1, 0), (0, -1)]:\n",
    "                    ny = row + neighbour[0]\n",
    "                    nx = element + neighbour[1]\n",
    "            \n",
    "                    # Skip if the pixel is out-of-bounds\n",
    "                    if ny < 0 or ny > coral_matrix.shape[0] - 1 or nx < 0 or nx > coral_matrix.shape[1] - 1:\n",
    "                        continue\n",
    "                        \n",
    "                    # If neighbour is sea, the cell is an edge.\n",
    "                    if coral_matrix[ny, nx] == 0:\n",
    "                        edge_cells.add((row, element))\n",
    "                        break\n",
    "\n",
    "    return len(edge_cells) / coral_size\n",
    "\n",
    "\n",
    "def fractal_dimension(N, object_mat, file=None):\n",
    "    \"\"\"\n",
    "    Function to calculate the fractal dimension of the object. \n",
    "    \n",
    "    Parameters:\n",
    "      - N: The width/height of the box we simulate\n",
    "      - object_mat: The N x N matrix describing the coral\n",
    "      - file: If not None, writes to disk instead of showing the plots\n",
    "           \n",
    "    Returns:\n",
    "    Box-counts for different box sizes, fractal dimension.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Define a local function to compute the powerlaw\n",
    "    func_powerlaw = lambda x, k, c, c0: c0 + x**k * c\n",
    "    # Define a local function to plot a straight line\n",
    "    line = lambda m, x, b: m*x+b\n",
    "    \n",
    "    # Find amount of different block sizes (here = 6)\n",
    "    size = N\n",
    "    m = int(np.log(size)/np.log(2))\n",
    "\n",
    "    # List to save the counts of the blocks containing a '1'\n",
    "    cnts = []\n",
    "\n",
    "    # For each in the different block sizes, calculate a block size, and find how many of the blocks contain '1'\n",
    "    for lev in range(m):\n",
    "        block_size = 2**lev\n",
    "        cnt = 0\n",
    "        for j in range(int(size/(2*block_size))):\n",
    "            for i in range(int(size/block_size)):\n",
    "                cnt = cnt + object_mat[j*block_size:(j+1)*block_size, i*block_size:(i+1)*block_size].any()\n",
    "        cnts.append(cnt)\n",
    "\n",
    "    # Set block size + amount of blocks containing a '1' in a data array\n",
    "    data = np.array([(2**(m-(k+1)),cnts[k]) for k in range(m)])\n",
    "    xs = data[:,0]\n",
    "    ys = data[:,1]\n",
    "\n",
    "    # Calculate logs + plot the points\n",
    "    xs_log = np.log(data[:,0])\n",
    "    ys_log = np.log(data[:,1])\n",
    "    plt.plot(xs_log, ys_log, 'o')\n",
    "\n",
    "    # Fit a straight line through log plots, slope = fractal dimension\n",
    "    A = np.vstack([xs_log, np.ones(len(xs))]).T\n",
    "    fract_dim, b = np.linalg.lstsq(A, ys_log, rcond=-1)[0]\n",
    "    \n",
    "    ys_fitted = line(fract_dim, xs_log, b)\n",
    "\n",
    "    # Plot the fitted line\n",
    "    plt.plot(xs_log, ys_fitted)\n",
    "    plt.title('Fitted line through log of box-counts')\n",
    "    if file is None:\n",
    "        plt.show()\n",
    "    else:\n",
    "        plt.savefig(\"box-count-plot.png\")\n",
    "\n",
    "    # Plot the log-log plot of the data (shows log axes)\n",
    "    plt.loglog(data[:,0],data[:,1])\n",
    "    plt.title('Log-log plot of box-counts')\n",
    "    if file is None:\n",
    "        plt.show()\n",
    "    else:\n",
    "        plt.savefig(\"box-count-log-log-plot.png\")\n",
    "\n",
    "    # Fit a powerlaw through the points and plot\n",
    "    popt, pcov = curve_fit(func_powerlaw, data[:,0], data[:,1])\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    plt.plot(data[:,0], func_powerlaw(data[:,0], *popt), '--')\n",
    "    plt.plot(data[:,0], data[:,1], 'ro')\n",
    "    if file is None:\n",
    "        plt.show()\n",
    "    else:\n",
    "        plt.savefig(\"box-count-log-log-plot.png\")\n",
    "    \n",
    "    print('Fractal dimension: ', fract_dim)\n",
    "    return data, fract_dim\n",
    "\n",
    "\n",
    "def fractal_dimension_simple(N, object_mat):\n",
    "    \"\"\"\n",
    "    Function to calculate the fractal dimension of the object. \n",
    "    \n",
    "    Parameters:\n",
    "      - N: The width/height of the box we simulate\n",
    "      - object_mat: The N x N matrix describing the coral\n",
    "           \n",
    "    Returns:\n",
    "    Box-counts for different box sizes, fractal dimension.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Find amount of different block sizes (here = 6)\n",
    "    size = N\n",
    "    m = int(np.log(size)/np.log(2))\n",
    "\n",
    "    # List to save the counts of the blocks containing a '1'\n",
    "    cnts = []\n",
    "\n",
    "    # For each in the different block sizes, calculate a block size, and find how many of the blocks contain '1'\n",
    "    for lev in range(m):\n",
    "        block_size = 2**lev\n",
    "        cnt = 0\n",
    "        for j in range(int(size/(2*block_size))):\n",
    "            for i in range(int(size/block_size)):\n",
    "                cnt = cnt + object_mat[j*block_size:(j+1)*block_size, i*block_size:(i+1)*block_size].any()\n",
    "        cnts.append(cnt)\n",
    "\n",
    "    # Set block size + amount of blocks containing a '1' in a data array\n",
    "    data = np.array([(2**(m-(k+1)),cnts[k]) for k in range(m)])\n",
    "    xs = data[:,0]\n",
    "    ys = data[:,1]\n",
    "\n",
    "    # Calculate logs + plot the points\n",
    "    xs_log = np.log(data[:,0])\n",
    "    ys_log = np.log(data[:,1])\n",
    "\n",
    "    # Fit a straight line through log plots, slope = fractal dimension\n",
    "    A = np.vstack([xs_log, np.ones(len(xs))]).T\n",
    "    fract_dim, b = np.linalg.lstsq(A, ys_log, rcond=-1)[0]\n",
    "    \n",
    "    return data, fract_dim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cd0a522-bf08-4c78-96df-8437316efbde",
   "metadata": {},
   "outputs": [],
   "source": [
    "### PLOTTING\n",
    "\n",
    "def plot_object_gradient(conc_mat, object_mat, eta, file=None):\n",
    "    \"\"\"\n",
    "        Function to make a combined imshow plot, where the object is visible\n",
    "        along with the gradient.\n",
    "        \n",
    "        Code (with small adjustments) based on answer at:\n",
    "        https://stackoverflow.com/questions/10127284/overlay-imshow-plots-in-matplotlib\n",
    "        \n",
    "        Parameters:\n",
    "          - conc_mat: N x N matrix with the gradient to plot\n",
    "          - object_mat: N x N matrix with the coral to plot\n",
    "          - eta: weight of concentration gradient for growth\n",
    "          - file: If not None, writes to the given file instead of showing the\n",
    "            plot. (Default: None)\n",
    "    \"\"\"\n",
    "    \n",
    "    # Remove any previous bars\n",
    "    plt.clf()\n",
    "    \n",
    "    # Generate the colors for your colormap\n",
    "    color1 = colorConverter.to_rgba('white')\n",
    "    color2 = colorConverter.to_rgba('black')\n",
    "\n",
    "    # Make the colormaps\n",
    "    cmap2 = mpl.colors.LinearSegmentedColormap.from_list('my_cmap2', [color1,color2], 256)\n",
    "    cmap2._init() # create the _lut array, with rgba values\n",
    "\n",
    "    # Create your alpha array and fill the colormap with them.\n",
    "    #   Here it is progressive, but you can create whathever you want\n",
    "    alphas = np.linspace(0, 0.8, cmap2.N + 3)\n",
    "    cmap2._lut[:, -1] = alphas\n",
    "\n",
    "    img2 = plt.imshow(conc_mat, interpolation='nearest', cmap='Spectral', origin='lower', extent=[0, 1, 0, 1])\n",
    "    plt.colorbar()\n",
    "    img3 = plt.imshow(object_mat, interpolation='nearest', cmap=cmap2, origin='lower', extent=[0, 1, 0, 1])\n",
    "\n",
    "    plt.title(f\"Object with gradient, eta = {eta}\")\n",
    "\n",
    "    # Either show or save\n",
    "    if file is None:\n",
    "        plt.show()\n",
    "    else:\n",
    "        plt.savefig(file)\n",
    "\n",
    "         \n",
    "def snapshots_to_mp4(snapshots, snapshots_obj, eta, filename, temp_name=\"temp/<i>.png\", fps=25, mode=\"gradient\"):\n",
    "    \"\"\"\n",
    "        Function that plots the given list of snapshots and saves them as an\n",
    "        mp4. Note that the intermediate disk usage may be quite high, and that\n",
    "        we assume the ffmpeg Ubuntu exec is installed.\n",
    "        \n",
    "        If not, try:\n",
    "           sudo apt-get install ffmpeg\n",
    "        \n",
    "        Parameters:\n",
    "          - snapshots: the list of (gradient) snapshots we want to plot\n",
    "          - snapshots_obj: list of object matrices, showing the coral growth\n",
    "          - eta: weight of concentration gradient for growth\n",
    "          - filename: resulting name of the movie.\n",
    "          - temp_name: template for the intermediate pictures. Use '<i>' to\n",
    "            indicate where in the name the photo's index should be.\n",
    "            Default: 'temp/<i>.png'\n",
    "          - fps: the frames per second of the resulting image. (Default: 25)\n",
    "        \n",
    "        Returns:\n",
    "        Nothing directly, but the chosen filename should now exist as an .mp4\n",
    "    \"\"\"\n",
    "    \n",
    "    # First, check the temp_name validity\n",
    "    if temp_name.count(\"<i>\") != 1:\n",
    "        raise ValueError(\"temp_name should include exactly one '<i>' to indicate the number location\")\n",
    "    \n",
    "    # Sanity check that the two lists have the same length\n",
    "    if len(snapshots) != len(snapshots_obj):\n",
    "        raise ValueError(f\"snapshots and snapshots_obj do not have the same length ({len(snapshots)} vs {len(snapshots_obj)})\")\n",
    "        \n",
    "    # Generate a temp folder if it doesn't exist yet\n",
    "    dir_name = \"/\".join(temp_name.split(\"/\")[:-1])\n",
    "    if not os.path.isdir(dir_name):\n",
    "        os.mkdir(dir_name)\n",
    "    \n",
    "    # Before we run, delete the existing pics\n",
    "    os.system(f\"rm -f {temp_name.replace('<i>', '*')}\")\n",
    "    \n",
    "    # Next, start pumping out plots; but note file errors\n",
    "    try:\n",
    "        prgs = ProgressBar(width=100, max_amount=len(snapshots) - 1)\n",
    "        for i in range(len(snapshots)):\n",
    "            if mode == \"gradient\":\n",
    "                plot_object_gradient(snapshots[i], snapshots_obj[i], eta, temp_name.replace(\"<i>\", f\"{i:05d}\"))\n",
    "            elif mode == \"vector\":\n",
    "                plt.clf()\n",
    "                plt.vector_field(snapshots[i]);\n",
    "                plt.savefig(temp_name.replace(\"<i>\", f\"{i:05d}\"), dpi=200)\n",
    "            else:\n",
    "                raise ValueError(f\"Unknown mode '{mode}'\")\n",
    "            prgs.update()\n",
    "        \n",
    "    except OSError as e:\n",
    "        print(f\"ERROR: Could not write to file '{e.filename}': {e.strerror}\")\n",
    "        return\n",
    "    \n",
    "    # With that done, call ffmpeg\n",
    "    cmd = f\"ffmpeg -y -r {fps} -i {temp_name.replace('<i>', '%05d')} -c:v libx264 -pix_fmt yuv420p {filename}\"\n",
    "    print(f\"Combining images with: '{cmd}'\")\n",
    "    os.system(cmd)\n",
    "    \n",
    "    # Done!\n",
    "    \n",
    "\n",
    "def figure_coral_with_flow(scenario, mode=\"vector\", file=None):\n",
    "    \"\"\"\n",
    "        Function to plot the coral flow, either as vector field or as density\n",
    "        field.\n",
    "        \n",
    "        Parameters:\n",
    "          - scenario: LBMpy scenario describing the current flow\n",
    "          - mode: Draw mode, either 'vector' for vectors or 'scalar' for\n",
    "            density (default: vector).\n",
    "          - file: If not None, writes to the given file instead of showing the\n",
    "            plot. (Default: None)\n",
    "        \n",
    "        Returns:\n",
    "        Nothing, but does show a pyplot.\n",
    "    \"\"\"\n",
    "\n",
    "    plt.figure(dpi=200)\n",
    "    if mode == \"vector\":\n",
    "        plt.vector_field(scenario.velocity_slice());\n",
    "    elif mode == \"scalar\":\n",
    "        plt.scalar_field(scenario.velocity[:,:,0])\n",
    "    plt.colorbar()\n",
    "\n",
    "    # Either show or save\n",
    "    if file is None:\n",
    "        plt.show()\n",
    "    else:\n",
    "        plt.savefig(file)\n",
    "    \n",
    "    \n",
    "def amazing_graph(density_list):\n",
    "    \"\"\"\n",
    "        Function that makes a graph of the density of a matrix, saves all intermidiate plots in folder named amazing_graph\n",
    "        \n",
    "        Parameters:\n",
    "          - density_list \n",
    "        \n",
    "        Returns:\n",
    "        Fills field with graphs, make video with command :ffmpeg -i %04d.png -c:v libx264 -vf fps=2 -pix_fmt yuv420p test_out.mp4\n",
    "        Make sure to be in path of amazing_graph\n",
    "    \"\"\"\n",
    "    \n",
    "    for i in range(len(density_list)):\n",
    "        current = density_list[0:i]\n",
    "        plt.plot(current, color='green')\n",
    "        plt.xlabel(\"Step number\")\n",
    "        plt.ylabel(\"Average distance to seed\")\n",
    "        plt.title(\"Density of Coral over step \")\n",
    "        plt.savefig(f'amazing_graph/{i:04d}.png')\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68438aa6-fbc5-4c30-97cd-b4cea514beab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test run with just the sunlight computation\n",
    "\n",
    "N = 100\n",
    "eta = 1\n",
    "omega = 1.5\n",
    "alpha = 0.5\n",
    "threshold = 5\n",
    "nut_inflow = 0.3\n",
    "iterations = 100\n",
    "\n",
    "# Run the simulation\n",
    "snapshots_obj, snapshots_vel, snapshots_vec, snapshots_sun, snapshots_grad, density_list = SOR_DLA_to_solution(N, eta, omega, alpha, threshold, nut_inflow, iterations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30528657-a85e-45e4-81ea-abf9e50ec088",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plottie plottie :)\n",
    "plot_object_gradient(snapshots_grad[-1], snapshots_obj[-1], 1)\n",
    "print(f\"Final result of the simulation with\\n - N={N}\\n - eta={eta}\\n - omega={omega}\\n - alpha={alpha}\\n - threshold={threshold}\\n - nut_inflow={nut_inflow}\\n - iterations={iterations}\\n\")\n",
    "plt.plot(density_list)\n",
    "plt.show()\n",
    "print(f\"The branch factor of the coral during the simulation.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0c47748-a59a-4880-a16b-41958dd25590",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run to generate a movie of the nutrient concentrations across the simulation\n",
    "# Requires: ffmpeg package (on Ubuntu: \"sudo apt-get install ffmpeg\")\n",
    "snapshots_to_mp4(snapshots_grad[50:], snapshots_obj[50:], eta, \"gradient.mp4\", fps=25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24fb939b-0f16-4f5f-9946-fbe0ec074af4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run to generate a movie of the vector fields of Lattice-Boltzmann across the simulation\n",
    "# Requires: ffmpeg package (on Ubuntu: \"sudo apt-get install ffmpeg\")\n",
    "snapshots_to_mp4(snapshots_vec[:50] + snapshots_vec[2050:], snapshots_obj[:50] + snapshots_obj[2050:], eta, \"vectors.mp4\", fps=20, mode=\"vector\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24df4a76-c2d6-4155-aa62-7a67c31944c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute the fractal dimension, showing some nice plots\n",
    "box_counts, dim = fractal_dimension(N, snapshots_obj[-1])\n",
    "print(dim)\n",
    "print(box_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20086e06-14c6-4c80-b1d6-af42e9ab8c13",
   "metadata": {},
   "outputs": [],
   "source": [
    "### IO\n",
    "\n",
    "def load_experiment(zip_path, run = 0):\n",
    "    \"\"\"\n",
    "        Loads the .npy files collected during an experiment.\n",
    "        \n",
    "        Parameters:\n",
    "          - zip_path: Path to the .zip containing the experiment\n",
    "          - run: Which of the runs to load. (Default: 0)\n",
    "        \n",
    "        Returns:\n",
    "        A tuple of:\n",
    "          - objects snapshots\n",
    "          - velocity snapshots\n",
    "          - flow vector field snapshots\n",
    "          - sunlight snapshots\n",
    "          - nutrient gradient snapshots\n",
    "    \"\"\"\n",
    "    \n",
    "    # Load the zipfile\n",
    "    zipf = np.load(zip_path)\n",
    "    \n",
    "    # Determine the base path for the files\n",
    "    base_path = zip_path.replace(\".zip\", \"\") + f\"/run_{run:05d}\"\n",
    "    while base_path[0] == '/': base_path = base_path[1:]\n",
    "\n",
    "    # Load the individual arrays\n",
    "    snapshots_obj = zipf[base_path + \"/snapshots_obj\"]\n",
    "    snapshots_vel = zipf[base_path + \"/snapshots_vel\"]\n",
    "    snapshots_vec = zipf[base_path + \"/snapshots_vec\"]\n",
    "    snapshots_sun = zipf[base_path + \"/snapshots_sun\"]\n",
    "    snapshots_grad = zipf[base_path + \"/snapshots_grad\"]\n",
    "\n",
    "    # When done return them all\n",
    "    return snapshots_obj, snapshots_vel, snapshots_vec, snapshots_sun, snapshots_grad\n",
    "\n",
    "def load_experiment_unzipped(output_dir, run = 0):\n",
    "    \"\"\"\n",
    "        Also loads the .npy file generated using experiments.py, except that it\n",
    "        expectes the output to not be compressed in a .zip file.\n",
    "        \n",
    "        Parameters:\n",
    "          - zip_path: Path to the .zip containing the experiment\n",
    "          - run: Which of the runs to load. (Default: 0)\n",
    "        \n",
    "        Returns:\n",
    "        A tuple of:\n",
    "          - objects snapshots\n",
    "          - velocity snapshots\n",
    "          - flow vector field snapshots\n",
    "          - sunlight snapshots\n",
    "          - nutrient gradient snapshots\n",
    "    \"\"\"\n",
    "    \n",
    "    # Determine the base path for the files\n",
    "    base_path = output_dir + f\"/run_{run:05d}\"\n",
    "\n",
    "    # Load the individual arrays\n",
    "    snapshots_obj = np.load(base_path + \"/snapshots_obj.npy\")\n",
    "    snapshots_vel = np.load(base_path + \"/snapshots_vel.npy\")\n",
    "    snapshots_vec = np.load(base_path + \"/snapshots_vec.npy\")\n",
    "    snapshots_sun = np.load(base_path + \"/snapshots_sun.npy\")\n",
    "    snapshots_grad = np.load(base_path + \"/snapshots_grad.npy\")\n",
    "\n",
    "    # When done return them all\n",
    "    return snapshots_obj, snapshots_vel, snapshots_vec, snapshots_sun, snapshots_grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afa65052-06f7-4bf1-be20-a4a363c437e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "snapshots_obj, snapshots_vel, snapshots_vec, snapshots_sun, snapshots_grad = load_experiment(\"outputs/alpha/alpha_00.zip\", run=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41c00f78-c1a1-41a6-a17c-02838400d155",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_object_gradient(snapshots_grad[-1], snapshots_obj[-1], 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "050a9a5a-fe15-45dd-a373-02ed539b45b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_all_branchfactors(zip_path, alpha_val, var=\"alpha\", secondary_var=None, file=None, compressed=True):\n",
    "    \"\"\"\n",
    "        Plots the branchfactor of all testruns for the given alpha value, plus\n",
    "        an average. Uses a rather bad set of parameters to also work for the\n",
    "        different thresholds.\n",
    "        \n",
    "        Parameters:\n",
    "          - zip_path: Path to the zipfile (or folder) containing all the runs\n",
    "            for the given alpha value\n",
    "          - alpha_val: The value of the alpha for this set of testruns. Mainly\n",
    "            used for labels in the plot.\n",
    "          - var: The variable we vary. Usually set to 'alpha', but allows the\n",
    "            function to be used for thresholds instead. (Default: 'alpha')\n",
    "          - secondary_var: If set to something else to None, lists the value\n",
    "            for alpha as a second value in the plot (relevant for thresholds,\n",
    "            which is run for multiple alpha's). (Default: None)\n",
    "          - file: If set to anything other than None, writes the plot to disk\n",
    "            under the given name instead of showing it. (Default: None)\n",
    "          - compressed: If set to False, treats the given zip_path as an\n",
    "            uncompressed folder with subfolders instead. Use True to indicate\n",
    "            a normal zipfile. (Default: True)\n",
    "        \n",
    "        Returns:\n",
    "        A list that describes the average fractal dimension for the given\n",
    "        value.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Get the runs\n",
    "    runs = []\n",
    "    for i in range(10):\n",
    "        if compressed:\n",
    "            runs.append(load_experiment(zip_path, run=i))\n",
    "        else:\n",
    "            runs.append(load_experiment_unzipped(zip_path, run=i))\n",
    "    \n",
    "    # Next, start plotting\n",
    "    plt.clf()\n",
    "    \n",
    "    # Plot each of the run's density for the run's interesting times\n",
    "    avg = [0 for i in range(100)]\n",
    "    xs = range(100)\n",
    "    for run, (snapshots_obj, snapshots_vel, snapshots_vec, snapshots_sun, snapshots_grad) in enumerate(runs):\n",
    "        ys = [branch_factor(snapshot) for snapshot in snapshots_obj[2050:]]\n",
    "        plt.plot(xs, ys, alpha=0.25, label=f\"run {run}\")\n",
    "        \n",
    "        # Also add the averages\n",
    "        avg = [avg[i] + ys[i] for i in range(100)]\n",
    "    \n",
    "    # Finally, plot the average\n",
    "    avg = [val / len(runs) for val in avg]\n",
    "    plt.plot(xs, avg, label=\"average\")\n",
    "    plt.title(f\"Branch factor for {var}={alpha_val}\" + (\"\" if secondary_var is None else f\" & alpha={secondary_var}\"))\n",
    "    plt.xlabel(\"Iteration\")\n",
    "    plt.ylabel(\"Branch factor\")\n",
    "    plt.legend()\n",
    "    \n",
    "    # Show or save the plot\n",
    "    if file is None:\n",
    "        plt.show()\n",
    "    else:\n",
    "        plt.savefig(file)\n",
    "    \n",
    "    # Finally return the average for the joint plot\n",
    "    return avg\n",
    "\n",
    "\n",
    "def plot_all_fractals(zip_path, alpha_val, var=\"alpha\", secondary_var=None, file=None, compressed=True):\n",
    "    \"\"\"\n",
    "        Plots the fractals of all testruns for the given alpha value, plus\n",
    "        an average. Uses a rather bad set of parameters to also work for the\n",
    "        different thresholds.\n",
    "        \n",
    "        Parameters:\n",
    "          - zip_path: Path to the zipfile (or folder) containing all the runs\n",
    "            for the given alpha value\n",
    "          - alpha_val: The value of the alpha for this set of testruns. Mainly\n",
    "            used for labels in the plot.\n",
    "          - var: The variable we vary. Usually set to 'alpha', but allows the\n",
    "            function to be used for thresholds instead. (Default: 'alpha')\n",
    "          - secondary_var: If set to something else to None, lists the value\n",
    "            for alpha as a second value in the plot (relevant for thresholds,\n",
    "            which is run for multiple alpha's). (Default: None)\n",
    "          - file: If set to anything other than None, writes the plot to disk\n",
    "            under the given name instead of showing it. (Default: None)\n",
    "          - compressed: If set to False, treats the given zip_path as an\n",
    "            uncompressed folder with subfolders instead. Use True to indicate\n",
    "            a normal zipfile. (Default: True)\n",
    "        \n",
    "        Returns:\n",
    "        A list that describes the average fractal dimension for the given\n",
    "        value.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Get the runs\n",
    "    runs = []\n",
    "    for i in range(10):\n",
    "        if compressed:\n",
    "            runs.append(load_experiment(zip_path, run=i))\n",
    "        else:\n",
    "            runs.append(load_experiment_unzipped(zip_path, run=i))\n",
    "    \n",
    "    # Next, start plotting\n",
    "    plt.clf()\n",
    "    \n",
    "    # Plot each of the run's density for the run's interesting times\n",
    "    avg = [0 for i in range(100)]\n",
    "    xs = range(100)\n",
    "    for run, (snapshots_obj, snapshots_vel, snapshots_vec, snapshots_sun, snapshots_grad) in enumerate(runs):\n",
    "        ys = [fractal_dimension_simple(100, snapshot)[1] for snapshot in snapshots_obj[2050:]]\n",
    "        plt.plot(xs, ys, alpha=0.25, label=f\"run {run}\")\n",
    "        \n",
    "        # Also add the averages\n",
    "        avg = [avg[i] + ys[i] for i in range(100)]\n",
    "    \n",
    "    # Finally, plot the average\n",
    "    avg = [val / len(runs) for val in avg]\n",
    "    plt.plot(xs, avg, label=\"average\")\n",
    "    plt.title(f\"Fractal dimensions for {var}={alpha_val}\" + (\"\" if secondary_var is None else f\" & alpha={secondary_var}\"))\n",
    "    plt.xlabel(\"Iteration\")\n",
    "    plt.ylabel(\"Fractal dimension\")\n",
    "    plt.legend()\n",
    "    \n",
    "    # Show or save the plot\n",
    "    if file is None:\n",
    "        plt.show()\n",
    "    else:\n",
    "        plt.savefig(file)\n",
    "    \n",
    "    # Finally return the average for the joint plot\n",
    "    return avg\n",
    "\n",
    "\n",
    "def plot_all_averages(averages, var=\"alpha\", mode=\"Branch factor\", secondary_var=None, file=None):\n",
    "    \"\"\"\n",
    "        Given a dictionary of average branch factors or fractals, plots a graph\n",
    "        combining all of them.\n",
    "        \n",
    "        Parameters:\n",
    "          - averages: Dictionary of averages. The keys are the values for the\n",
    "            the lists of average values that follows.\n",
    "          - var: The variable we vary. (Default: \"alpha\")\n",
    "          - mode: The name of the parameter that we plot. (Default: \"Branch factor\")\n",
    "          - secondary_var: If set to something else to None, lists the value\n",
    "            for alpha as a second value in the plot (relevant for thresholds,\n",
    "            which is run for multiple alpha's). (Default: None)\n",
    "          - file: If set to anything other than None, writes the plot to disk\n",
    "            under the given name instead of showing it. (Default: None)\n",
    "        \n",
    "        Returns:\n",
    "        Nothing, but plots a graph :)\n",
    "    \"\"\"\n",
    "    \n",
    "    # Plot\n",
    "    plt.clf()\n",
    "    xs = range(100)\n",
    "    for value in averages:\n",
    "        plt.plot(xs, averages[value], label=f\"{var} = {value}\")\n",
    "    plt.title(f\"{mode} across {var}s\" + (\"\" if secondary_var is None else f\" for alpha={secondary_var}\"))\n",
    "    plt.xlabel(\"Iterations\")\n",
    "    plt.ylabel(f\"{mode} (avg)\")\n",
    "    plt.legend()\n",
    "    \n",
    "    # Show or save\n",
    "    if file is None:\n",
    "        plt.show()\n",
    "    else:\n",
    "        plt.savefig(file)\n",
    "\n",
    "        \n",
    "def plot_avg_averages(averages, mode=\"Branch factor\", file=None):\n",
    "    \"\"\"\n",
    "        Plots a graph combining multiple, total averages. The averages should\n",
    "        be computed beforehand, and is thus mostly different titles when\n",
    "        compared to plot_all_averages().\n",
    "        \n",
    "        Parameters:\n",
    "          - averages: list of averages, with the keys the values themselves\n",
    "            and the values as lists\n",
    "          - mode: The parameter we plot.\n",
    "          - file: If set to anything other than None, writes the plot to disk\n",
    "            under the given name instead of showing it. (Default: None)\n",
    "        \n",
    "        Returns:\n",
    "        Nothing, but does produce a dope plot\n",
    "    \"\"\"\n",
    "    \n",
    "    # Do the plot\n",
    "    plt.clf()\n",
    "    xs = range(100)\n",
    "    for value in averages:\n",
    "        plt.plot(xs, averages[value], label=f\"alpha = {value}\")\n",
    "    plt.title(f\"{mode} across the tested alphas\")\n",
    "    plt.xlabel(\"Iterations\")\n",
    "    plt.ylabel(f\"{mode} (avg)\")\n",
    "    plt.legend()\n",
    "    \n",
    "    # Show or save\n",
    "    if file is None:\n",
    "        plt.show()\n",
    "    else:\n",
    "        plt.savefig(file)\n",
    "\n",
    "        \n",
    "def save_run_mp4(zip_path, run, alpha_val, eta, var=\"alpha\", prefix=\"\", fps=15, compressed=True):\n",
    "    \"\"\"\n",
    "        Wrapper around snapshots_to_mp4 that first loads the data from the\n",
    "        given zipfile.\n",
    "        \n",
    "        Parameters:\n",
    "          - zip_path: Path to the zipfile (or folder) where the .npy of the\n",
    "            experiments that were run\n",
    "          - run: The number of the run we want to select.\n",
    "          - alpha_val: Value of the alpha that we are running on.\n",
    "          - eta: weight of concentration gradient for growth\n",
    "          - var: The variable we vary. (Default: \"alpha\")\n",
    "          - prefix: A bit of string to prefix to filename of the movie.\n",
    "            (Default: \"\")\n",
    "          - fps: Frames per second for the output MP4. (Default: 15)\n",
    "          - compressed: If set to False, treats the zip_path as an uncompressed\n",
    "            folder containing subfolders for the run. If True, treats it as\n",
    "            zipfile. (Default: True)\n",
    "    \"\"\"\n",
    "    \n",
    "    # First, load the zip's contents for this run\n",
    "    if compressed:\n",
    "        snapshots_obj, _, _, _, snapshots_grad = load_experiment(zip_path, run=run)\n",
    "    else:\n",
    "        snapshots_obj, _, _, _, snapshots_grad = load_experiment_unzipped(zip_path, run=run)\n",
    "    \n",
    "    # Take the snapshots for this run, and plot it\n",
    "    snapshots_to_mp4(snapshots_grad[2050:], snapshots_obj[2050:], eta, prefix + f\"{var}_{str(alpha_val).replace('.', '')}_{run}.mp4\", fps=fps)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e962b341-40f4-4b7e-86db-39de08961100",
   "metadata": {},
   "source": [
    "## Plotting from experiments\n",
    "From here on out, we plot all graphs we want for the presentation. There are three types of cells:\n",
    "  - Cells with multiple plot_all_*: here, we load the data, plot the per-parameter values in their plots and compute averages\n",
    "  - Cells with plot_all_averages (or plot_avg_averages): Combines the averages computed before in an overview graph\n",
    "  - Cells with save_run_mp4: Creates videos from the data on the disk (i.e., also loads it).\n",
    "  \n",
    "Note that these cells require data generated by experiments.py to be present in the located folders. Will probably throw errors if there isn't any."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99dcc0d2-774c-42b7-841a-207b7b5921a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_alpha_00 = plot_all_branchfactors(\"outputs/alpha/alpha_00.zip\", 0.0, file=\"alpha_0_0.png\")\n",
    "avg_alpha_025 = plot_all_branchfactors(\"outputs/alpha/alpha_025.zip\", 0.25, file=\"alpha_0_25.png\")\n",
    "avg_alpha_05 = plot_all_branchfactors(\"outputs/alpha/alpha_05.zip\", 0.5, file=\"alpha_0_5.png\")\n",
    "avg_alpha_075 = plot_all_branchfactors(\"outputs/alpha/alpha_075.zip\", 0.75, file=\"alpha_0_75.png\")\n",
    "avg_alpha_10 = plot_all_branchfactors(\"outputs/alpha/alpha_10.zip\", 1.0, file=\"alpha_1_0.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "750338ef-f85c-478a-8485-5cb766183780",
   "metadata": {},
   "outputs": [],
   "source": [
    "averages = {\n",
    "    0.0: [avg / 10 for avg in avg_alpha_00],\n",
    "    0.25: [avg / 10 for avg in avg_alpha_025],\n",
    "    0.5: [avg / 10 for avg in avg_alpha_05],\n",
    "    0.75: [avg / 10 for avg in avg_alpha_075],\n",
    "    1.0: [avg / 10 for avg in avg_alpha_10],\n",
    "}\n",
    "plot_all_averages(averages, file=\"alpha_combined.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13d551a9-d13c-48f4-928b-cad195c8bf17",
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_alpha_fract_00 = plot_all_fractals(\"outputs/alpha/alpha_00.zip\", 0.0, file=\"alpha_0_0_fract.png\")\n",
    "avg_alpha_fract_025 = plot_all_fractals(\"outputs/alpha/alpha_025.zip\", 0.25, file=\"alpha_0_25_fract.png\")\n",
    "avg_alpha_fract_05 = plot_all_fractals(\"outputs/alpha/alpha_05.zip\", 0.5, file=\"alpha_0_5_fract.png\")\n",
    "avg_alpha_fract_075 = plot_all_fractals(\"outputs/alpha/alpha_075.zip\", 0.75, file=\"alpha_0_75_fract.png\")\n",
    "avg_alpha_fract_10 = plot_all_fractals(\"outputs/alpha/alpha_10.zip\", 1.0, file=\"alpha_1_0_fract.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce7ceae3-5aad-40b8-b0e3-45e24c9040bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "averages = {\n",
    "    0.0: avg_alpha_fract_00,\n",
    "    0.25: avg_alpha_fract_025,\n",
    "    0.5: avg_alpha_fract_05,\n",
    "    0.75: avg_alpha_fract_075,\n",
    "    1.0: avg_alpha_fract_10\n",
    "}\n",
    "plot_all_averages(averages, file=\"alpha_combined_fract.png\", mode=\"Fractal dimension\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "228b9c17-fccc-4d91-bf9a-96a3c587cc35",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_run_mp4(\"outputs/alpha/alpha_00.zip\", 2, 0.0, 1.0, fps=10)\n",
    "save_run_mp4(\"outputs/alpha/alpha_025.zip\", 1, 0.25, 1.0, fps=10)\n",
    "save_run_mp4(\"outputs/alpha/alpha_05.zip\", 9, 0.5, 1.0, fps=10)\n",
    "save_run_mp4(\"outputs/alpha/alpha_075.zip\", 0, 0.75, 1.0, fps=10)\n",
    "save_run_mp4(\"outputs/alpha/alpha_10.zip\", 8, 1.0, 1.0, fps=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38878c4e-6e1f-4f71-94c3-82ce829f32a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Note to self: for thresholds, try to stay around 0.0500 - 0.0505 - 0.0510, maybe a _few_ larger variations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b3b8802-1b8f-46fd-9c28-4591714d45de",
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_threshold_00 = plot_all_branchfactors(\"outputs/threshold/threshold_00.zip\", 0.0, var=\"threshold\", secondary_var=0.0, file=\"threshold_0_0.png\")\n",
    "avg_threshold_00503 = plot_all_branchfactors(\"outputs/threshold/threshold_00503.zip\", 0.0503, var=\"threshold\", secondary_var=0.0, file=\"threshold_0_0503.png\")\n",
    "avg_threshold_00504 = plot_all_branchfactors(\"outputs/threshold/threshold_00504.zip\", 0.0504, var=\"threshold\", secondary_var=0.0, file=\"threshold_0_0504.png\")\n",
    "avg_threshold_00505 = plot_all_branchfactors(\"outputs/threshold/threshold_00505.zip\", 0.0505, var=\"threshold\", secondary_var=0.0, file=\"threshold_0_0505.png\")\n",
    "avg_threshold_00506 = plot_all_branchfactors(\"outputs/threshold/threshold_00506.zip\", 0.0506, var=\"threshold\", secondary_var=0.0, file=\"threshold_0_0506.png\")\n",
    "avg_threshold_00507 = plot_all_branchfactors(\"outputs/threshold/threshold_00507.zip\", 0.0507, var=\"threshold\", secondary_var=0.0, file=\"threshold_0_0507.png\")\n",
    "avg_threshold_01 = plot_all_branchfactors(\"outputs/threshold/threshold_01\", 0.1, var=\"threshold\", secondary_var=0.0, file=\"threshold_0_1.png\", compressed=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78f93682-6904-4a73-803e-3b4ac7c2bf95",
   "metadata": {},
   "outputs": [],
   "source": [
    "averages = {\n",
    "    0.0: avg_threshold_00,\n",
    "    0.0503: avg_threshold_00503,\n",
    "    0.0504: avg_threshold_00504,\n",
    "    0.0505: avg_threshold_00505,\n",
    "    0.0506: avg_threshold_00506,\n",
    "    0.0507: avg_threshold_00507,\n",
    "    0.1: avg_threshold_01\n",
    "}\n",
    "plot_all_averages(averages, var=\"threshold\", secondary_var=0.0, file=\"threshold_combined.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06bdfa38-6661-4aac-84b5-df68de7c2a04",
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_threshold_00_alpha_10 = plot_all_branchfactors(\"outputs/threshold/alpha_10/threshold_00\", 0.0, var=\"threshold\", secondary_var=1.0, file=\"threshold_0_0_alpha_10.png\", compressed=False)\n",
    "avg_threshold_00503_alpha_10 = plot_all_branchfactors(\"outputs/threshold/alpha_10/threshold_00503\", 0.0503, var=\"threshold\", secondary_var=1.0, file=\"threshold_0_0503_alpha_10.png\", compressed=False)\n",
    "avg_threshold_00504_alpha_10 = plot_all_branchfactors(\"outputs/threshold/alpha_10/threshold_00504\", 0.0504, var=\"threshold\", secondary_var=1.0, file=\"threshold_0_0504_alpha_10.png\", compressed=False)\n",
    "avg_threshold_00505_alpha_10 = plot_all_branchfactors(\"outputs/threshold/alpha_10/threshold_00505\", 0.0505, var=\"threshold\", secondary_var=1.0, file=\"threshold_0_0505_alpha_10.png\", compressed=False)\n",
    "avg_threshold_00506_alpha_10 = plot_all_branchfactors(\"outputs/threshold/alpha_10/threshold_00506\", 0.0506, var=\"threshold\", secondary_var=1.0, file=\"threshold_0_0506_alpha_10.png\", compressed=False)\n",
    "avg_threshold_00507_alpha_10 = plot_all_branchfactors(\"outputs/threshold/alpha_10/threshold_00507\", 0.0507, var=\"threshold\", secondary_var=1.0, file=\"threshold_0_0507_alpha_10.png\", compressed=False)\n",
    "avg_threshold_01_alpha_10 = plot_all_branchfactors(\"outputs/threshold/alpha_10/threshold_01\", 0.1, var=\"threshold\", secondary_var=1.0, file=\"threshold_0_1_alpha_10.png\", compressed=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af2163f1-56f2-4d71-8e58-e3d9866cf8c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "averages = {\n",
    "    0.0: avg_threshold_00_alpha_10,\n",
    "    0.0503: avg_threshold_00503_alpha_10,\n",
    "    0.0504: avg_threshold_00504_alpha_10,\n",
    "    0.0505: avg_threshold_00505_alpha_10,\n",
    "    0.0506: avg_threshold_00506_alpha_10,\n",
    "    0.0507: avg_threshold_00507_alpha_10,\n",
    "    0.1: avg_threshold_01_alpha_10,\n",
    "}\n",
    "plot_all_averages(averages, var=\"threshold\", secondary_var=1.0, file=\"threshold_combined_alpha_10.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab15c72b-a3a5-4793-a6e9-cd07c2a235bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "averages = {\n",
    "    0.0: [(avg_threshold_00[i] + avg_threshold_00503[i] + avg_threshold_00504[i] + avg_threshold_00505[i] + avg_threshold_00506[i] + avg_threshold_00507[i] + avg_threshold_01[i]) / 7 for i in range(len(avg_threshold_00))],\n",
    "    1.0: [(avg_threshold_00_alpha_10[i] + avg_threshold_00503_alpha_10[i] + avg_threshold_00504_alpha_10[i] + avg_threshold_00505_alpha_10[i] + avg_threshold_00506_alpha_10[i] + avg_threshold_00507_alpha_10[i] + avg_threshold_01_alpha_10[i]) / 7 for i in range(len(avg_threshold_00))]\n",
    "}\n",
    "plot_avg_averages(averages, file=\"threshold_combined_combined.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ee20b3a-c4d6-4b08-b40b-6b0dae7fb7c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_threshold_00_fractal = plot_all_fractals(\"outputs/threshold/threshold_00.zip\", 0.0, var=\"threshold\", secondary_var=0.0, file=\"threshold_0_0_fractal.png\")\n",
    "avg_threshold_00503_fractal = plot_all_fractals(\"outputs/threshold/threshold_00503.zip\", 0.0503, var=\"threshold\", secondary_var=0.0, file=\"threshold_0_0503_fractal.png\")\n",
    "avg_threshold_00504_fractal = plot_all_fractals(\"outputs/threshold/threshold_00504.zip\", 0.0504, var=\"threshold\", secondary_var=0.0, file=\"threshold_0_0504_fractal.png\")\n",
    "avg_threshold_00505_fractal = plot_all_fractals(\"outputs/threshold/threshold_00505.zip\", 0.0505, var=\"threshold\", secondary_var=0.0, file=\"threshold_0_0505_fractal.png\")\n",
    "avg_threshold_00506_fractal = plot_all_fractals(\"outputs/threshold/threshold_00506.zip\", 0.0506, var=\"threshold\", secondary_var=0.0, file=\"threshold_0_0506_fractal.png\")\n",
    "avg_threshold_00507_fractal = plot_all_fractals(\"outputs/threshold/threshold_00507.zip\", 0.0507, var=\"threshold\", secondary_var=0.0, file=\"threshold_0_0507_fractal.png\")\n",
    "avg_threshold_01_fractal = plot_all_fractals(\"outputs/threshold/threshold_01\", 0.1, var=\"threshold\", secondary_var=0.0, file=\"threshold_0_1_fractal.png\", compressed=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71a7e31e-207e-4ffc-bb28-34f5ea0039e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "averages = {\n",
    "    0.0: avg_threshold_00_fractal,\n",
    "    0.0503: avg_threshold_00503_fractal,\n",
    "    0.0504: avg_threshold_00504_fractal,\n",
    "    0.0505: avg_threshold_00505_fractal,\n",
    "    0.0506: avg_threshold_00506_fractal,\n",
    "    0.0507: avg_threshold_00507_fractal,\n",
    "    0.1: avg_threshold_01_fractal,\n",
    "}\n",
    "plot_all_averages(averages, var=\"threshold\", secondary_var=0.0, mode=\"Fractal dimension\", file=\"threshold_combined_fractal.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e8a784e-c9ea-4066-bd78-fd1577e46698",
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_threshold_00_alpha_10_fractal = plot_all_fractals(\"outputs/threshold/alpha_10/threshold_00\", 0.0, var=\"threshold\", secondary_var=1.0, file=\"threshold_0_0_alpha_10_fractal.png\", compressed=False)\n",
    "avg_threshold_00503_alpha_10_fractal = plot_all_fractals(\"outputs/threshold/alpha_10/threshold_00503\", 0.0503, var=\"threshold\", secondary_var=1.0, file=\"threshold_0_0503_alpha_10_fractal.png\", compressed=False)\n",
    "avg_threshold_00504_alpha_10_fractal = plot_all_fractals(\"outputs/threshold/alpha_10/threshold_00504\", 0.0504, var=\"threshold\", secondary_var=1.0, file=\"threshold_0_0504_alpha_10_fractal.png\", compressed=False)\n",
    "avg_threshold_00505_alpha_10_fractal = plot_all_fractals(\"outputs/threshold/alpha_10/threshold_00505\", 0.0505, var=\"threshold\", secondary_var=1.0, file=\"threshold_0_0505_alpha_10_fractal.png\", compressed=False)\n",
    "avg_threshold_00506_alpha_10_fractal = plot_all_fractals(\"outputs/threshold/alpha_10/threshold_00506\", 0.0506, var=\"threshold\", secondary_var=1.0, file=\"threshold_0_0506_alpha_10_fractal.png\", compressed=False)\n",
    "avg_threshold_00507_alpha_10_fractal = plot_all_fractals(\"outputs/threshold/alpha_10/threshold_00507\", 0.0507, var=\"threshold\", secondary_var=1.0, file=\"threshold_0_0507_alpha_10_fractal.png\", compressed=False)\n",
    "avg_threshold_01_alpha_10_fractal = plot_all_fractals(\"outputs/threshold/alpha_10/threshold_01\", 0.1, var=\"threshold\", secondary_var=1.0, file=\"threshold_0_1_alpha_10_fractal.png\", compressed=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed628116-1662-46f7-88af-bed19ee1062f",
   "metadata": {},
   "outputs": [],
   "source": [
    "averages = {\n",
    "    0.0: avg_threshold_00_alpha_10_fractal,\n",
    "    0.0503: avg_threshold_00503_alpha_10_fractal,\n",
    "    0.0504: avg_threshold_00504_alpha_10_fractal,\n",
    "    0.0505: avg_threshold_00505_alpha_10_fractal,\n",
    "    0.0506: avg_threshold_00506_alpha_10_fractal,\n",
    "    0.0507: avg_threshold_00507_alpha_10_fractal,\n",
    "    0.1: avg_threshold_01_alpha_10_fractal,\n",
    "}\n",
    "plot_all_averages(averages, var=\"threshold\", secondary_var=1.0, mode=\"Fractal dimension\", file=\"threshold_combined_alpha_10_fractal.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "632b2209-5804-4ace-9705-cd800decc588",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_run_mp4(\"outputs/threshold/threshold_00.zip\", 0, 0.0, 1.0, var=\"threshold\", fps=10)\n",
    "save_run_mp4(\"outputs/threshold/threshold_00503.zip\", 8, 0.0503, 1.0, var=\"threshold\", fps=10)\n",
    "save_run_mp4(\"outputs/threshold/threshold_00504.zip\", 3, 0.0504, 1.0, var=\"threshold\", fps=10)\n",
    "save_run_mp4(\"outputs/threshold/threshold_00505.zip\", 8, 0.0505, 1.0, var=\"threshold\", fps=10)\n",
    "save_run_mp4(\"outputs/threshold/threshold_00506.zip\", 1, 0.0506, 1.0, var=\"threshold\", fps=10)\n",
    "save_run_mp4(\"outputs/threshold/threshold_00507.zip\", 9, 0.0507, 1.0, var=\"threshold\", fps=10)\n",
    "save_run_mp4(\"outputs/threshold/threshold_01\", 7, 0.1, 1.0, var=\"threshold\", fps=10, compressed=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "698e3e29-3505-4e62-8462-6b644438a9c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_run_mp4(\"outputs/threshold/alpha_10/threshold_00\", 0, 0.0, 1.0, prefix=\"alpha_10_\", var=\"threshold\", fps=10, compressed=False)\n",
    "save_run_mp4(\"outputs/threshold/alpha_10/threshold_00503\", 9, 0.0503, 1.0, prefix=\"alpha_10_\", var=\"threshold\", fps=10, compressed=False)\n",
    "save_run_mp4(\"outputs/threshold/alpha_10/threshold_00504\", 1, 0.0504, 1.0, prefix=\"alpha_10_\", var=\"threshold\", fps=10, compressed=False)\n",
    "save_run_mp4(\"outputs/threshold/alpha_10/threshold_00505\", 4, 0.0505, 1.0, prefix=\"alpha_10_\", var=\"threshold\", fps=10, compressed=False)\n",
    "save_run_mp4(\"outputs/threshold/alpha_10/threshold_00506\", 6, 0.0506, 1.0, prefix=\"alpha_10_\", var=\"threshold\", fps=10, compressed=False)\n",
    "save_run_mp4(\"outputs/threshold/alpha_10/threshold_00507\", 7, 0.0507, 1.0, prefix=\"alpha_10_\", var=\"threshold\", fps=10, compressed=False)\n",
    "save_run_mp4(\"outputs/threshold/alpha_10/threshold_01\", 9, 0.1, 1.0, prefix=\"alpha_10_\", var=\"threshold\", fps=10, compressed=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "412bb2cc-d19d-4b3e-aecf-e80794d105fd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
